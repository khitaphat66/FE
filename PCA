## Import the Iris dataset from scikit-learn
#import matplotlib.pyplot as plt
#from sklearn.datasets import load_iris
#
## Load the Iris dataset
#iris = load_iris()
#
## Create X and Y variables to hold features and response column
#iris_X, iris_Y = iris.data, iris.target
#
## The names of the flower we are trying to predict
#iris.target_names
#
## Look at the names of the features
#iris.feature_names
#
## For labeling
#label_dict = {i: k for i, k in enumerate(iris.target_names)}  # {0: ‘setosa’, 1: ‘versicolor’, 2: ‘virginica’}
#
#
## Define a plotting function
#def plot(X, Y, title, x_label, y_label):
#    plt.figure(figsize=(8, 6))
#    for label, marker, color in zip(range(3), ('^', 's', 'o'), ('blue', 'red', 'green')):
#        plt.scatter(X[Y == label, 0], X[Y == label, 1], marker=marker, color=color, alpha=0.5, label=label_dict[label])
#
#    plt.xlabel(x_label)
#    plt.ylabel(y_label)
#    plt.legend(loc='upper right', fancybox=True)
#    plt.title(title)
#    plt.show()
#
#
## Plot the original Iris data
#plot(iris_X, iris_Y, "Original Iris Data", "Sepal Length (cm)", "Sepal Width (cm)")

#import numpy as np
#import matplotlib.pyplot as plt
#from sklearn.datasets import load_iris
#
## Load the Iris dataset
#iris = load_iris()
#iris_X = iris.data
#
## Calculate the mean vector
#mean_vector = iris_X.mean(axis=0)
#print("Mean Vector:", mean_vector)
#
## Calculate the covariance matrix
#cov_mat = np.cov((iris_X - mean_vector).T)
#print("Covariance Matrix Shape:", cov_mat.shape)
#
## Calculate the eigenvectors and eigenvalues of the covariance matrix
#eig_val_cov, eig_vec_cov = np.linalg.eig(cov_mat)
#
## Print the eigenvectors and corresponding eigenvalues in order of descending eigenvalues
#for i in range(len(eig_val_cov)):
#    eigvec_cov = eig_vec_cov[:, i]
#    print("Eigen Vector {}: {} with Eigenvalue {}".format(i + 1, eigvec_cov, eig_val_cov[i]))
#    print(30 * "-")
#
## The percentage of the variance captured by each eigenvalue
#variance_ratio = eig_val_cov / eig_val_cov.sum()
#print("Variance Ratio:", variance_ratio)
#
## Scree Plot
#plt.plot(np.cumsum(variance_ratio))
#plt.title('Scree Plot')
#plt.xlabel('Principal Component (k)')
#plt.ylabel('% of Variance Explained <= k')
#plt.grid()
#plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
iris_X = iris.data
iris_Y = iris.target

# Calculate the mean vector
mean_vector = iris_X.mean(axis=0)

# Calculate the covariance matrix
cov_mat = np.cov((iris_X - mean_vector).T)

# Calculate the eigenvectors and eigenvalues of the covariance matrix
eig_val_cov, eig_vec_cov = np.linalg.eig(cov_mat)

# Get the top 2 eigenvectors
top_2_eigenvectors = eig_vec_cov[:, :2]  # Corrected to use the first two eigenvectors
print("Top 2 Eigenvectors:\n", top_2_eigenvectors)

# Transform data from shape (150, 4) to (150, 2)
new_data = np.dot(iris_X, top_2_eigenvectors)
print("Transformed Data (first 5 rows):\n", new_data[:5])

# For labeling
label_dict = {i: k for i, k in enumerate(iris.target_names)}  # Create label dictionary

# Define the plot function
def plot(X, Y, title, x_label, y_label):
    plt.figure(figsize=(8, 6))
    for label, marker, color in zip(range(3), ('o', 'o', 'o'), ('blue', 'red', 'green')):
        plt.scatter(X[Y == label, 0], X[Y == label, 1], marker=marker, color=color, alpha=0.5, label=label_dict[label])

    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(loc='upper right', fancybox=True)
    plt.title(title)
    plt.grid()
    plt.show()

# Plot the transformed data
plot(new_data, iris_Y, "Iris Data Transformation with PCA", 'PCA 1', 'PCA 2')
